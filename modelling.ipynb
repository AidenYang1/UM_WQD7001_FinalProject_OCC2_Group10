{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelling (Refactored)\n",
        "\n",
        "- 前置：需先运行 `DataCleaning&EDA_refactored.ipynb` 生成 `heart_data_cleaned.csv`\n",
        "- 任务：训练分类模型（含聚类特征）、评估、导出模型与元数据\n",
        "- 产物：`best_classification_model.joblib`、`best_model_metadata.json`、`sample_input_5rows.csv`\n",
        "- 不包含：数据清洗、部署/Streamlit\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clean shape: (918, 12)\n",
            "Logistic best params: {'cluster__n_clusters': 3, 'model__C': 0.1, 'model__penalty': 'l2', 'model__solver': 'lbfgs'}, best CV recall: 0.884\n",
            "RandomForest best params: {'cluster__n_clusters': 5, 'model__max_depth': None, 'model__min_samples_leaf': 2, 'model__n_estimators': 200}, best CV recall: 0.890\n",
            "=== Best Model ===\n",
            "Name: RandomForest\n",
            "Test metrics: {'accuracy': 0.8913043478260869, 'precision': 0.896774193548387, 'recall': 0.9084967320261438, 'f1': 0.9025974025974026, 'roc_auc': 0.9410701950156757, 'cm': [[107, 16], [14, 139]]}\n",
            "Saved model -> outputs/best_classification_model.joblib\n",
            "Saved meta -> outputs/best_model_metadata.json\n",
            "Saved sample -> outputs/sample_input_5rows.csv\n",
            "下一步：在 Streamlit_refactored.ipynb 或 app.py 启动前端。\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix)\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import joblib\n",
        "\n",
        "DATA_PATH = \"heart_data_cleaned.csv\"\n",
        "ARTIFACT_DIR = Path(\"outputs\")\n",
        "ARTIFACT_DIR.mkdir(exist_ok=True)\n",
        "MODEL_PATH = ARTIFACT_DIR / \"best_classification_model.joblib\"\n",
        "META_PATH = ARTIFACT_DIR / \"best_model_metadata.json\"\n",
        "SAMPLE_PATH = ARTIFACT_DIR / \"sample_input_5rows.csv\"\n",
        "\n",
        "# 1) 加载清洗后数据\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Clean shape:\", df.shape)\n",
        "\n",
        "# 2) 目标与特征\n",
        "\n",
        "y = df[\"HeartDisease\"].map({\"No\": 0, \"Yes\": 1}).astype(int) if df[\"HeartDisease\"].dtype == object else df[\"HeartDisease\"].astype(int)\n",
        "X = df.drop(columns=[\"HeartDisease\"])\n",
        "\n",
        "# 3) 自定义聚类特征\n",
        "\n",
        "class ClusterFeatureAdder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cluster_cols=None, n_clusters=4, random_state=42):\n",
        "        self.cluster_cols = cluster_cols\n",
        "        self.n_clusters = n_clusters\n",
        "        self.random_state = random_state\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        cols = self.cluster_cols or [\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]\n",
        "        self.cols_ = cols\n",
        "        self.scaler_ = StandardScaler()\n",
        "        Z = self.scaler_.fit_transform(X[cols])\n",
        "        self.kmeans_ = KMeans(n_clusters=self.n_clusters, n_init=10, random_state=self.random_state)\n",
        "        self.kmeans_.fit(Z)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        Xc = X.copy()\n",
        "        Z = self.scaler_.transform(Xc[self.cols_])\n",
        "        labels = self.kmeans_.predict(Z)\n",
        "        Xc[\"cluster_label\"] = labels.astype(str)\n",
        "        return Xc\n",
        "\n",
        "# 4) 预处理\n",
        "\n",
        "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=[\"object\", \"bool\", \"category\"]).columns.tolist()\n",
        "\n",
        "numeric_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline([\n",
        "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "])\n",
        "\n",
        "def make_preprocessor():\n",
        "    return ColumnTransformer([\n",
        "        (\"num\", numeric_transformer, numeric_features),\n",
        "        (\"cat\", categorical_transformer, categorical_features + [\"cluster_label\"]),\n",
        "    ])\n",
        "\n",
        "# 5) 划分数据\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# 6) Pipeline + GridSearch（Logistic 与 RF）\n",
        "\n",
        "cluster = ClusterFeatureAdder()\n",
        "\n",
        "logi = Pipeline([\n",
        "    (\"cluster\", cluster),\n",
        "    (\"prep\", make_preprocessor()),\n",
        "    (\"model\", LogisticRegression(max_iter=200, n_jobs=-1)),\n",
        "])\n",
        "\n",
        "rf = Pipeline([\n",
        "    (\"cluster\", cluster),\n",
        "    (\"prep\", make_preprocessor()),\n",
        "    (\"model\", RandomForestClassifier(random_state=42, n_jobs=-1)),\n",
        "])\n",
        "\n",
        "logi_grid = {\n",
        "    \"cluster__n_clusters\": [3, 4, 5],\n",
        "    \"model__C\": [0.1, 0.5, 1.0],\n",
        "    \"model__penalty\": [\"l2\"],\n",
        "    \"model__solver\": [\"lbfgs\"],\n",
        "}\n",
        "\n",
        "rf_grid = {\n",
        "    \"cluster__n_clusters\": [3, 4, 5],\n",
        "    \"model__n_estimators\": [200, 400],\n",
        "    \"model__max_depth\": [None, 8, 12],\n",
        "    \"model__min_samples_leaf\": [1, 2],\n",
        "}\n",
        "\n",
        "models = []\n",
        "for name, pipe, grid in [\n",
        "    (\"Logistic\", logi, logi_grid),\n",
        "    (\"RandomForest\", rf, rf_grid),\n",
        "]:\n",
        "    gs = GridSearchCV(pipe, grid, cv=4, scoring=\"recall\", n_jobs=-1)\n",
        "    gs.fit(X_train, y_train)\n",
        "    models.append((name, gs))\n",
        "    print(f\"{name} best params: {gs.best_params_}, best CV recall: {gs.best_score_:.3f}\")\n",
        "\n",
        "# 7) 选最佳并在测试集评估\n",
        "\n",
        "def eval_model(model, Xte, yte):\n",
        "    proba = model.predict_proba(Xte)[:, 1]\n",
        "    pred = (proba >= 0.5).astype(int)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(yte, pred),\n",
        "        \"precision\": precision_score(yte, pred),\n",
        "        \"recall\": recall_score(yte, pred),\n",
        "        \"f1\": f1_score(yte, pred),\n",
        "        \"roc_auc\": roc_auc_score(yte, proba),\n",
        "        \"cm\": confusion_matrix(yte, pred).tolist(),\n",
        "    }\n",
        "\n",
        "best_name, best_gs = max(models, key=lambda t: t[1].best_score_)\n",
        "best_model = best_gs.best_estimator_\n",
        "\n",
        "metrics = eval_model(best_model, X_test, y_test)\n",
        "print(\"=== Best Model ===\")\n",
        "print(\"Name:\", best_name)\n",
        "print(\"Test metrics:\", metrics)\n",
        "\n",
        "# 8) 导出模型与元数据\n",
        "\n",
        "joblib.dump(best_model, MODEL_PATH)\n",
        "print(\"Saved model ->\", MODEL_PATH)\n",
        "\n",
        "meta = {\n",
        "    \"final_model_name\": best_name,\n",
        "    \"best_params\": best_gs.best_params_,\n",
        "    \"test_set_performance\": metrics,\n",
        "    \"expected_input_columns\": X.columns.tolist(),\n",
        "}\n",
        "Path(META_PATH).write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
        "print(\"Saved meta ->\", META_PATH)\n",
        "\n",
        "# 导出示例输入\n",
        "X.sample(5, random_state=42).to_csv(SAMPLE_PATH, index=False)\n",
        "print(\"Saved sample ->\", SAMPLE_PATH)\n",
        "\n",
        "print(\"下一步：在 Streamlit_refactored.ipynb 或 app.py 启动前端。\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
